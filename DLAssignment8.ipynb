{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DEEP LEARNING ASSIGNMENT 8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RACHIT AGGARWAL = M12506500"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rachi\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /tmp/data/train-images-idx3-ubyte.gz\n",
      "Extracting /tmp/data/train-labels-idx1-ubyte.gz\n",
      "Extracting /tmp/data/t10k-images-idx3-ubyte.gz\n",
      "Extracting /tmp/data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"/tmp/data/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8 (a)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "he_init = tf.contrib.layers.variance_scaling_initializer()\n",
    "\n",
    "def dnn(inputs, n_hidden_layers=5, n_neurons=100, name=None,\n",
    "        activation=tf.nn.elu, initializer=he_init):\n",
    "    with tf.variable_scope(name, \"dnn\"):\n",
    "        for layer in range(n_hidden_layers):\n",
    "            inputs = tf.layers.dense(inputs, n_neurons, activation=activation,\n",
    "                                     kernel_initializer=initializer,\n",
    "                                     name=\"hidden%d\" % (layer + 1))\n",
    "        return inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def reset_graph(seed=42):\n",
    "    tf.reset_default_graph()\n",
    "    tf.set_random_seed(seed)\n",
    "    np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_inputs = 28 * 28 # MNIST\n",
    "n_outputs = 5\n",
    "\n",
    "reset_graph()\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape=(None, n_inputs), name=\"X\")\n",
    "y = tf.placeholder(tf.int64, shape=(None), name=\"y\")\n",
    "\n",
    "dnn_outputs = dnn(X)\n",
    "\n",
    "logits = tf.layers.dense(dnn_outputs, n_outputs, kernel_initializer=he_init, name=\"logits\")\n",
    "Y_proba = tf.nn.softmax(logits, name=\"Y_proba\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8 (b)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "learning_rate = 0.01\n",
    "\n",
    "xentropy = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y, logits=logits)\n",
    "loss = tf.reduce_mean(xentropy, name=\"loss\")\n",
    "\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate)\n",
    "training_op = optimizer.minimize(loss, name=\"training_op\")\n",
    "\n",
    "correct = tf.nn.in_top_k(logits, y, 1)\n",
    "accuracy = tf.reduce_mean(tf.cast(correct, tf.float32), name=\"accuracy\")\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train1 = mnist.train.images[mnist.train.labels < 5]\n",
    "y_train1 = mnist.train.labels[mnist.train.labels < 5]\n",
    "X_valid1 = mnist.validation.images[mnist.validation.labels < 5]\n",
    "y_valid1 = mnist.validation.labels[mnist.validation.labels < 5]\n",
    "X_test1 = mnist.test.images[mnist.test.labels < 5]\n",
    "y_test1 = mnist.test.labels[mnist.test.labels < 5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\tValidation loss: 0.190826\tBest loss: 0.190826\tAccuracy: 96.64%\n",
      "1\tValidation loss: 1.689649\tBest loss: 0.190826\tAccuracy: 18.73%\n",
      "2\tValidation loss: 1.660114\tBest loss: 0.190826\tAccuracy: 20.91%\n",
      "3\tValidation loss: 1.778077\tBest loss: 0.190826\tAccuracy: 22.01%\n",
      "4\tValidation loss: 1.667106\tBest loss: 0.190826\tAccuracy: 22.01%\n",
      "5\tValidation loss: 1.654532\tBest loss: 0.190826\tAccuracy: 22.01%\n",
      "6\tValidation loss: 1.680933\tBest loss: 0.190826\tAccuracy: 18.73%\n",
      "7\tValidation loss: 1.779077\tBest loss: 0.190826\tAccuracy: 22.01%\n",
      "8\tValidation loss: 1.699482\tBest loss: 0.190826\tAccuracy: 19.27%\n",
      "9\tValidation loss: 1.767771\tBest loss: 0.190826\tAccuracy: 20.91%\n",
      "10\tValidation loss: 1.629350\tBest loss: 0.190826\tAccuracy: 22.01%\n",
      "11\tValidation loss: 1.812643\tBest loss: 0.190826\tAccuracy: 22.01%\n",
      "12\tValidation loss: 1.675939\tBest loss: 0.190826\tAccuracy: 18.73%\n",
      "13\tValidation loss: 1.633259\tBest loss: 0.190826\tAccuracy: 20.91%\n",
      "14\tValidation loss: 1.652904\tBest loss: 0.190826\tAccuracy: 20.91%\n",
      "15\tValidation loss: 1.635943\tBest loss: 0.190826\tAccuracy: 20.91%\n",
      "16\tValidation loss: 1.718915\tBest loss: 0.190826\tAccuracy: 19.08%\n",
      "17\tValidation loss: 1.682456\tBest loss: 0.190826\tAccuracy: 19.27%\n",
      "18\tValidation loss: 1.675366\tBest loss: 0.190826\tAccuracy: 18.73%\n",
      "19\tValidation loss: 1.645805\tBest loss: 0.190826\tAccuracy: 19.08%\n",
      "20\tValidation loss: 1.722336\tBest loss: 0.190826\tAccuracy: 22.01%\n",
      "Early stopping!\n",
      "INFO:tensorflow:Restoring parameters from ./my_mnist_model_0_to_4.ckpt\n",
      "Final test accuracy: 97.08%\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 1000\n",
    "batch_size = 20\n",
    "\n",
    "max_checks_without_progress = 20\n",
    "checks_without_progress = 0\n",
    "best_loss = np.infty\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "\n",
    "    for epoch in range(n_epochs):\n",
    "        rnd_idx = np.random.permutation(len(X_train1))\n",
    "        for rnd_indices in np.array_split(rnd_idx, len(X_train1) // batch_size):\n",
    "            X_batch, y_batch = X_train1[rnd_indices], y_train1[rnd_indices]\n",
    "            sess.run(training_op, feed_dict={X: X_batch, y: y_batch})\n",
    "        loss_val, acc_val = sess.run([loss, accuracy], feed_dict={X: X_valid1, y: y_valid1})\n",
    "        if loss_val < best_loss:\n",
    "            save_path = saver.save(sess, \"./my_mnist_model_0_to_4.ckpt\")\n",
    "            best_loss = loss_val\n",
    "            checks_without_progress = 0\n",
    "        else:\n",
    "            checks_without_progress += 1\n",
    "            if checks_without_progress > max_checks_without_progress:\n",
    "                print(\"Early stopping!\")\n",
    "                break\n",
    "        print(\"{}\\tValidation loss: {:.6f}\\tBest loss: {:.6f}\\tAccuracy: {:.2f}%\".format(\n",
    "            epoch, loss_val, best_loss, acc_val * 100))\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    saver.restore(sess, \"./my_mnist_model_0_to_4.ckpt\")\n",
    "    acc_test = accuracy.eval(feed_dict={X: X_test1, y: y_test1})\n",
    "    print(\"Final test accuracy: {:.2f}%\".format(acc_test * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9 (a)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "reset_graph()\n",
    "\n",
    "restore_saver = tf.train.import_meta_graph(\"./my_mnist_model_0_to_4.ckpt.meta\")\n",
    "\n",
    "X = tf.get_default_graph().get_tensor_by_name(\"X:0\")\n",
    "y = tf.get_default_graph().get_tensor_by_name(\"y:0\")\n",
    "loss = tf.get_default_graph().get_tensor_by_name(\"loss:0\")\n",
    "Y_proba = tf.get_default_graph().get_tensor_by_name(\"Y_proba:0\")\n",
    "logits = Y_proba.op.inputs[0]\n",
    "accuracy = tf.get_default_graph().get_tensor_by_name(\"accuracy:0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "learning_rate = 0.01\n",
    "\n",
    "output_layer_vars = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, scope=\"logits\")\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate, name=\"Adam2\")\n",
    "training_op = optimizer.minimize(loss, var_list=output_layer_vars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "correct = tf.nn.in_top_k(logits, y, 1)\n",
    "accuracy = tf.reduce_mean(tf.cast(correct, tf.float32), name=\"accuracy\")\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "five_frozen_saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9 (b)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train2_full = mnist.train.images[mnist.train.labels >= 5]\n",
    "y_train2_full = mnist.train.labels[mnist.train.labels >= 5] - 5\n",
    "X_valid2_full = mnist.validation.images[mnist.validation.labels >= 5]\n",
    "y_valid2_full = mnist.validation.labels[mnist.validation.labels >= 5] - 5\n",
    "X_test2 = mnist.test.images[mnist.test.labels >= 5]\n",
    "y_test2 = mnist.test.labels[mnist.test.labels >= 5] - 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sample_n_instances_per_class(X, y, n=100):\n",
    "    Xs, ys = [], []\n",
    "    for label in np.unique(y):\n",
    "        idx = (y == label)\n",
    "        Xc = X[idx][:n]\n",
    "        yc = y[idx][:n]\n",
    "        Xs.append(Xc)\n",
    "        ys.append(yc)\n",
    "    return np.concatenate(Xs), np.concatenate(ys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train2, y_train2 = sample_n_instances_per_class(X_train2_full, y_train2_full, n=100)\n",
    "X_valid2, y_valid2 = sample_n_instances_per_class(X_valid2_full, y_valid2_full, n=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./my_mnist_model_0_to_4.ckpt\n",
      "0\tValidation loss: 1.428894\tBest loss: 1.428894\tAccuracy: 47.33%\n",
      "1\tValidation loss: 1.278391\tBest loss: 1.278391\tAccuracy: 49.33%\n",
      "2\tValidation loss: 1.166970\tBest loss: 1.166970\tAccuracy: 52.67%\n",
      "3\tValidation loss: 1.308910\tBest loss: 1.166970\tAccuracy: 49.33%\n",
      "4\tValidation loss: 1.133370\tBest loss: 1.133370\tAccuracy: 54.67%\n",
      "5\tValidation loss: 1.264265\tBest loss: 1.133370\tAccuracy: 50.67%\n",
      "6\tValidation loss: 1.167142\tBest loss: 1.133370\tAccuracy: 52.67%\n",
      "7\tValidation loss: 1.201874\tBest loss: 1.133370\tAccuracy: 52.00%\n",
      "8\tValidation loss: 1.233133\tBest loss: 1.133370\tAccuracy: 51.33%\n",
      "9\tValidation loss: 1.144155\tBest loss: 1.133370\tAccuracy: 56.00%\n",
      "10\tValidation loss: 1.203532\tBest loss: 1.133370\tAccuracy: 54.00%\n",
      "11\tValidation loss: 1.225048\tBest loss: 1.133370\tAccuracy: 54.67%\n",
      "12\tValidation loss: 1.110734\tBest loss: 1.110734\tAccuracy: 53.33%\n",
      "13\tValidation loss: 1.260934\tBest loss: 1.110734\tAccuracy: 53.33%\n",
      "14\tValidation loss: 1.187337\tBest loss: 1.110734\tAccuracy: 52.67%\n",
      "15\tValidation loss: 1.277027\tBest loss: 1.110734\tAccuracy: 50.00%\n",
      "16\tValidation loss: 1.331769\tBest loss: 1.110734\tAccuracy: 47.33%\n",
      "17\tValidation loss: 1.315484\tBest loss: 1.110734\tAccuracy: 53.33%\n",
      "18\tValidation loss: 1.364839\tBest loss: 1.110734\tAccuracy: 50.00%\n",
      "19\tValidation loss: 1.240890\tBest loss: 1.110734\tAccuracy: 51.33%\n",
      "20\tValidation loss: 1.272402\tBest loss: 1.110734\tAccuracy: 54.00%\n",
      "21\tValidation loss: 1.188019\tBest loss: 1.110734\tAccuracy: 53.33%\n",
      "22\tValidation loss: 1.247131\tBest loss: 1.110734\tAccuracy: 52.67%\n",
      "23\tValidation loss: 1.182870\tBest loss: 1.110734\tAccuracy: 58.00%\n",
      "24\tValidation loss: 1.254077\tBest loss: 1.110734\tAccuracy: 56.00%\n",
      "25\tValidation loss: 1.191344\tBest loss: 1.110734\tAccuracy: 54.67%\n",
      "26\tValidation loss: 1.221578\tBest loss: 1.110734\tAccuracy: 54.67%\n",
      "27\tValidation loss: 1.200133\tBest loss: 1.110734\tAccuracy: 51.33%\n",
      "28\tValidation loss: 1.162464\tBest loss: 1.110734\tAccuracy: 56.00%\n",
      "29\tValidation loss: 1.215864\tBest loss: 1.110734\tAccuracy: 56.00%\n",
      "30\tValidation loss: 1.172153\tBest loss: 1.110734\tAccuracy: 55.33%\n",
      "31\tValidation loss: 1.231002\tBest loss: 1.110734\tAccuracy: 49.33%\n",
      "32\tValidation loss: 1.199356\tBest loss: 1.110734\tAccuracy: 54.67%\n",
      "Early stopping!\n",
      "Total training time: 4.2s\n",
      "INFO:tensorflow:Restoring parameters from ./my_mnist_model_5_to_9_five_frozen\n",
      "Final test accuracy: 57.50%\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 1000\n",
    "batch_size = 20\n",
    "\n",
    "max_checks_without_progress = 20\n",
    "checks_without_progress = 0\n",
    "best_loss = np.infty\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    restore_saver.restore(sess, \"./my_mnist_model_0_to_4.ckpt\")\n",
    "    for var in output_layer_vars:\n",
    "        var.initializer.run()\n",
    "\n",
    "    t0 = time.time()\n",
    "        \n",
    "    for epoch in range(n_epochs):\n",
    "        rnd_idx = np.random.permutation(len(X_train2))\n",
    "        for rnd_indices in np.array_split(rnd_idx, len(X_train2) // batch_size):\n",
    "            X_batch, y_batch = X_train2[rnd_indices], y_train2[rnd_indices]\n",
    "            sess.run(training_op, feed_dict={X: X_batch, y: y_batch})\n",
    "        loss_val, acc_val = sess.run([loss, accuracy], feed_dict={X: X_valid2, y: y_valid2})\n",
    "        if loss_val < best_loss:\n",
    "            save_path = five_frozen_saver.save(sess, \"./my_mnist_model_5_to_9_five_frozen\")\n",
    "            best_loss = loss_val\n",
    "            checks_without_progress = 0\n",
    "        else:\n",
    "            checks_without_progress += 1\n",
    "            if checks_without_progress > max_checks_without_progress:\n",
    "                print(\"Early stopping!\")\n",
    "                break\n",
    "        print(\"{}\\tValidation loss: {:.6f}\\tBest loss: {:.6f}\\tAccuracy: {:.2f}%\".format(\n",
    "            epoch, loss_val, best_loss, acc_val * 100))\n",
    "\n",
    "    t1 = time.time()\n",
    "    print(\"Total training time: {:.1f}s\".format(t1 - t0))\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    five_frozen_saver.restore(sess, \"./my_mnist_model_5_to_9_five_frozen\")\n",
    "    acc_test = accuracy.eval(feed_dict={X: X_test2, y: y_test2})\n",
    "    print(\"Final test accuracy: {:.2f}%\".format(acc_test * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Determining correctly and missclassfied instances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./my_mnist_model_5_to_9_five_frozen\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    five_frozen_saver.restore(sess, \"./my_mnist_model_5_to_9_five_frozen\")\n",
    "    prediction = correct.eval(feed_dict={X: X_test2, y: y_test2})  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([False,  True, False, ...,  True, False,  True])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Separating instances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame(prediction, columns=['pred'])\n",
    "X_test2_df = pd.DataFrame(X_test2)\n",
    "new_df = pd.concat((df, X_test2_df),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "correctly_classified = new_df[new_df.pred == True]\n",
    "miss_classified = new_df[new_df.pred == False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "correctly_classified = correctly_classified.drop(['pred'], axis=1)\n",
    "miss_classified = miss_classified.drop(['pred'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selecting 100 correct and 100 missclassified examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "correct_calss = correctly_classified[:100].as_matrix()\n",
    "wrong_calss = miss_classified[:100].as_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 784)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wrong_calss.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ploting a random correctly classified instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-0.5, 27.5, 27.5, -0.5)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nH0KJH0KJH0L9F+kPBawJ/W0OAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x233bd583748>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(correct_calssi_mat[28,:].reshape(28,28),cmap='binary')\n",
    "plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ploting a random wrongly classified instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-0.5, 27.5, 27.5, -0.5)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nHnsSpuYr8y4AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x233bd512cf8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(wrong_calssi_mat[28,:].reshape(28,28),cmap='binary')\n",
    "plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
